{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import gzip, pickle\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from fastcore.test import test_close\n",
    "from functools import reduce\n",
    "import random\n",
    "from itertools import islice\n",
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('data/mnist.pkl.gz')\n",
    "with gzip.open(data_path, \"rb\") as f :\n",
    "    ((x_train,y_train),(x_valid, y_valid),_) = pickle.load(f,encoding=\"latin-1\")\n",
    "x_train,y_train,x_valid, y_valid = map(tensor,[x_train,y_train,x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self.layers = [nn.Linear(n_in, nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "\n",
    "    def __call__(self,x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "pred = model(x_train)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return (x.exp()/(x.exp().sum(dim=1,keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
       "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
       "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
       "        ...,\n",
       "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
       "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
       "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<LogBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x - x.exp().sum(dim=1,keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
       "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
       "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
       "        ...,\n",
       "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
       "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
       "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x):\n",
    "    a = x.max(dim=1)[0]\n",
    "    return a + (x-a[:,None]).exp().sum(dim=1).log() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
       "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
       "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
       "        ...,\n",
       "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
       "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
       "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred-logsumexp(pred)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    return x - logsumexp(x)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_pred = log_softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(sm_pred, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.36, -2.28, -2.09,  ..., -2.43, -2.47, -2.11],\n",
       "        [-2.37, -2.25, -2.09,  ..., -2.46, -2.43, -2.11],\n",
       "        [-2.34, -2.31, -2.14,  ..., -2.44, -2.48, -2.14],\n",
       "        ...,\n",
       "        [-2.26, -2.25, -2.13,  ..., -2.36, -2.53, -2.17],\n",
       "        [-2.39, -2.30, -2.18,  ..., -2.38, -2.42, -2.11],\n",
       "        [-2.40, -2.25, -2.14,  ..., -2.38, -2.45, -2.23]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.log_softmax(pred,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.31, 2.31, 2.29,  ..., 2.34, 2.32, 2.32], grad_fn=<LogsumexpBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.logsumexp(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(pred-pred.logsumexp(-1)[:,None],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.nll_loss(F.log_softmax(pred,-1),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.30, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(pred,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 50\n",
    "lr = 0.5\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50]), torch.Size([50]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_train[0:bs]).argmax(dim=1).shape, y_train[0:bs].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, targ): return (out.argmax(dim=1)==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model(x_train[0:bs]),y_train[0:bs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(out, targ): print(f'loss: {loss_func(out, targ):.2f}, accuracy: {accuracy(out, targ):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.30, accuracy: 0.13\n"
     ]
    }
   ],
   "source": [
    "report(pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 6.84, accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "model = Model(m, nh, 10)\n",
    "bs = 50\n",
    "lr = 0.5\n",
    "epochs = 3\n",
    "xb, yb = x_train[:bs], y_train[:bs]\n",
    "report(xb,yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.12, accuracy: 0.96\n",
      "loss: 0.09, accuracy: 0.96\n",
      "loss: 0.10, accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i,min(n,i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred,yb)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l,\"weight\"):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.data.zero_()\n",
    "                    l.bias.grad.data.zero_()\n",
    "    report(pred, yb) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Linear(in_features=784, out_features=50, bias=True)\n",
      "1 ReLU()\n",
      "2 Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for i,l in enumerate (model.children()): print(i,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f6336e5f530>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            s = slice(i,min(n,i+bs))\n",
    "            xb, yb = x_train[s], y_train[s]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred,yb)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): \n",
    "                    p -= p.grad * lr\n",
    "                model.zero_grad() \n",
    "        report(pred, yb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, l in enumerate (self.layers): self.add_module(f'layer_{i}',l)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return reduce(lambda val, layer: layer(val), self.layers, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13, accuracy: 0.96\n",
      "loss: 0.10, accuracy: 0.96\n",
      "loss: 0.06, accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules_register = {}\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "\n",
    "    def __setattr__(self, k, v):\n",
    "        if not k.startswith('_'): self._modules_register[k]=v\n",
    "        super().__setattr__(k,v)\n",
    "    \n",
    "    def __repr__(self): return f'{self._modules_register}'\n",
    "\n",
    "    def parameters(self): \n",
    "        for l in self._modules_register.values(): yield from l.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModule(m,nh,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters(): print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer():\n",
    "    def __init__(self, parameters, lr=lr): \n",
    "        self.parameters = list(parameters) ; self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.parameters:\n",
    "                p -= p.grad * self.lr\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters: p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return (model, Optimizer(model.parameters())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.15, accuracy: 0.94\n",
      "loss: 0.08, accuracy: 0.96\n",
      "loss: 0.06, accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i,min(n,i+bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred,yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(pred, yb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, inp, targ): self.inp, self.targ = inp, targ\n",
    "\n",
    "    def __len__(self): return len(self.inp)\n",
    "\n",
    "    def __getitem__(self, idx): return self.inp[idx], self.targ[idx] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = train_ds[0:bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.16, accuracy: 0.96\n",
      "loss: 0.11, accuracy: 0.96\n",
      "loss: 0.05, accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        xb, yb = train_ds[i:min(n,i+bs)]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred,yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(pred, yb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader():\n",
    "    def __init__(self, ds, bs): self.ds, self.bs = ds, bs\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i:min(n,i+bs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_valid = Dataloader(train_ds, bs), Dataloader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.14, accuracy: 0.92\n",
      "loss: 0.11, accuracy: 0.96\n",
      "loss: 0.07, accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in dl_train:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred,yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(pred, yb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), torch.Size([50]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(dl_train)\n",
    "xb, yb = next(it)\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "        3, 9, 8, 5, 9, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(dl_train))\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[3].view(28,28))\n",
    "yb[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, shuffle = False): self.ds, self.shuffle = ds, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        res = list(range(len(self.ds)))\n",
    "        if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = Sampler(train_ds)\n",
    "it = iter(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    def __init__(self, sampler, bs, drop_last=False): fc.store_attr()\n",
    "    def __iter__(self): yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs),torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, collate_fn=collate): fc.store_attr()\n",
    "    def __iter__(self): yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = BatchSampler(Sampler(train_ds, shuffle=True ), bs)\n",
    "valid_samp = BatchSampler(Sampler(valid_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batchs=train_samp)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('a', 'c'), ('b', 'd'))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [('a',\"b\"),('c',\"d\")]\n",
    "xs, ys = zip(*a)\n",
    "xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.01, 0.07,\n",
      "        0.07, 0.07, 0.49, 0.53, 0.68, 0.10, 0.65, 1.00, 0.96, 0.50, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.12, 0.14, 0.37, 0.60, 0.66, 0.99, 0.99, 0.99, 0.99, 0.99, 0.88, 0.67, 0.99, 0.95, 0.76, 0.25, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.19, 0.93, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.99, 0.98, 0.36, 0.32, 0.32, 0.22, 0.15, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.07, 0.86, 0.99, 0.99, 0.99, 0.99, 0.99, 0.77, 0.71, 0.96, 0.94,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.31, 0.61, 0.42, 0.99,\n",
      "        0.99, 0.80, 0.04, 0.00, 0.17, 0.60, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.05, 0.00, 0.60, 0.99, 0.35, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.54, 0.99, 0.74, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.04, 0.74, 0.99, 0.27, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.14, 0.94, 0.88, 0.62, 0.42, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.32, 0.94, 0.99, 0.99, 0.46, 0.10, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.18, 0.73, 0.99, 0.99, 0.59, 0.11,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.06, 0.36, 0.98, 0.99, 0.73, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.97, 0.99, 0.97, 0.25, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.18, 0.51, 0.71, 0.99, 0.99, 0.81, 0.01, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.15, 0.58, 0.89, 0.99, 0.99, 0.99,\n",
      "        0.98, 0.71, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.09, 0.45,\n",
      "        0.86, 0.99, 0.99, 0.99, 0.99, 0.79, 0.30, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.09, 0.26, 0.83, 0.99, 0.99, 0.99, 0.99, 0.77, 0.32, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.07, 0.67, 0.86, 0.99, 0.99, 0.99, 0.99, 0.76, 0.31, 0.04, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.21, 0.67, 0.88, 0.99, 0.99, 0.99, 0.99, 0.95, 0.52, 0.04, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.53, 0.99, 0.99, 0.99, 0.83, 0.53,\n",
      "        0.52, 0.06, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]), tensor(5)) (tensor([0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.20, 0.62, 0.99, 0.62, 0.20,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.19, 0.93, 0.98, 0.98, 0.98, 0.93, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.21, 0.89, 0.99, 0.98, 0.93, 0.91, 0.98, 0.22, 0.02, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.04, 0.23, 0.88, 0.98, 0.99, 0.98, 0.79, 0.33, 0.98, 0.99, 0.48, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.64, 0.98, 0.98, 0.98, 0.99, 0.98, 0.98,\n",
      "        0.38, 0.74, 0.99, 0.65, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.20, 0.93,\n",
      "        0.99, 0.99, 0.74, 0.45, 0.99, 0.89, 0.18, 0.31, 1.00, 0.66, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.19, 0.93, 0.98, 0.98, 0.70, 0.05, 0.29, 0.47, 0.08, 0.00, 0.00, 0.99, 0.95, 0.20, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.15, 0.64, 0.99, 0.91, 0.81, 0.33, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.99, 0.98,\n",
      "        0.64, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.03, 0.70, 0.98, 0.94, 0.28, 0.07, 0.11, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.99, 0.98, 0.76, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.22, 0.98, 0.98,\n",
      "        0.25, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.99, 0.98, 0.76, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.77, 0.99, 0.74, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 1.00, 0.99, 0.77, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.30, 0.96, 0.98, 0.44, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.99, 0.98, 0.58, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.33, 0.98, 0.90, 0.10, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.03, 0.53, 0.99, 0.73, 0.05, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.33, 0.98,\n",
      "        0.87, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.03, 0.51, 0.98, 0.88, 0.28, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.33, 0.98, 0.57, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.19, 0.64, 0.98, 0.68, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.34, 0.99, 0.88, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.45, 0.93, 0.99,\n",
      "        0.63, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.33, 0.98, 0.97, 0.57, 0.19, 0.11,\n",
      "        0.33, 0.70, 0.88, 0.99, 0.87, 0.65, 0.22, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.33, 0.98, 0.98, 0.98, 0.89, 0.84, 0.98, 0.98, 0.98, 0.77, 0.51, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.11, 0.78, 0.98, 0.98, 0.99, 0.98, 0.98, 0.91, 0.57, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.10, 0.50, 0.98, 0.99, 0.98, 0.55, 0.14, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n",
      "        0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "def test(b):\n",
    "    print(*b)\n",
    "\n",
    "b = [0,1]\n",
    "test(train_ds[i] for i in b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import store_attr\n",
    "class Dataloader_MT():\n",
    "    def __init__(self, ds, bs, shuffle=False): fc.store_attr()\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.res = list(range(len(self.ds)))\n",
    "        if self.shuffle: random.shuffle(self.res)\n",
    "        for i in fc.chunked(iter(self.res), self.bs):\n",
    "            yield self.ds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_mt = Dataloader_MT(train_ds, bs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dl_mt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f6336dcef50>, tensor(5))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28)),yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls (train_ds, valid_ds, bs, **kwargs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
    "        DataLoader(valid_ds, batch_size=bs*2, shuffle=False, **kwargs)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 784]), 50)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "xb.shape, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func ,opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss = loss_func(model(xb),yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            count, total_accuracy, total_loss = 0, 0. ,0.\n",
    "            for xb, yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                loss = loss_func(pred,yb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                total_accuracy += accuracy(pred,yb).item()*n\n",
    "                total_loss     += loss_func(pred,yb).item()*n\n",
    "            \n",
    "        print(epochs,total_loss/count, total_accuracy/count)\n",
    "        \n",
    "    return total_loss/count, total_accuracy/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.1513418527878821 0.9561000049114228\n",
      "3 0.12390999983996152 0.9651000082492829\n",
      "3 0.1282746159657836 0.9634000033140182\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = fit(epochs, model, loss_func ,opt, train_dl, valid_dl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, targ): return (out.argmax(dim=1)==targ).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchSampler_MT():\n",
    "    def __init__(self, sampler, bs): fc.store_attr()\n",
    "\n",
    "    def __iter__():\n",
    "        yield from fc.chunked(self.sampler, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader2():\n",
    "    def __init__(self,ds,batchsamp): fc.store_attr()\n",
    "\n",
    "    def __iter__():\n",
    "        yield from (collate(ds[i] for i in b) for b in self.batchsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
